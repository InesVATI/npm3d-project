
@misc{thomas_semantic_2018,
	title = {Semantic Classification of 3D Point Clouds with Multiscale Spherical Neighborhoods},
	url = {http://arxiv.org/abs/1808.00495},
	abstract = {This paper introduces a new definition of multiscale neighborhoods in 3D point clouds. This definition, based on spherical neighborhoods and proportional subsampling, allows the computation of features with a consistent geometrical meaning, which is not the case when using k-nearest neighbors. With an appropriate learning strategy, the proposed features can be used in a random forest to classify 3D points. In this semantic classification task, we show that our multiscale features outperform state-of-the-art features using the same experimental conditions. Furthermore, their classification power competes with more elaborate classification approaches including Deep Learning methods.},
	number = {{arXiv}:1808.00495},
	publisher = {{arXiv}},
	author = {Thomas, Hugues and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, François and Gall, Yann Le},
	urldate = {2024-01-30},
	date = {2018-08-01},
	eprinttype = {arxiv},
	eprint = {1808.00495 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{weinmann_semantic_2015,
	title = {Semantic point cloud interpretation based on optimal neighborhoods, relevant features and efficient classifiers},
	volume = {105},
	issn = {09242716},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271615000349},
	doi = {10.1016/j.isprsjprs.2015.01.016},
	pages = {286--304},
	journaltitle = {{ISPRS} Journal of Photogrammetry and Remote Sensing},
	shortjournal = {{ISPRS} Journal of Photogrammetry and Remote Sensing},
	author = {Weinmann, Martin and Jutzi, Boris and Hinz, Stefan and Mallet, Clément},
	urldate = {2024-01-31},
	date = {2015-07},
	langid = {english},
}

@article{hackel_fast_nodate,
	title = {{FAST} {SEMANTIC} {SEGMENTATION} {OF} 3D {POINT} {CLOUDS} {WITH} {STRONGLY} {VARYING} {DENSITY}},
	abstract = {We describe an effective and efﬁcient method for point-wise semantic classiﬁcation of 3D point clouds. The method can handle unstructured and inhomogeneous point clouds such as those derived from static terrestrial {LiDAR} or photogammetric reconstruction; and it is computationally efﬁcient, making it possible to process point clouds with many millions of points in a matter of minutes. The key issue, both to cope with strong variations in point density and to bring down computation time, turns out to be careful handling of neighborhood relations. By choosing appropriate deﬁnitions of a point’s (multi-scale) neighborhood, we obtain a feature set that is both expressive and fast to compute. We evaluate our classiﬁcation method both on benchmark data from a mobile mapping platform and on a variety of large, terrestrial laser scans with greatly varying point density. The proposed feature set outperforms the state of the art with respect to per-point classiﬁcation accuracy, while at the same time being much faster to compute.},
	author = {Hackel, Timo and Wegner, Jan D and Schindler, Konrad},
	langid = {english},
}

@misc{xiao_polarmix_2022,
	title = {{PolarMix}: A General Data Augmentation Technique for {LiDAR} Point Clouds},
	url = {http://arxiv.org/abs/2208.00223},
	shorttitle = {{PolarMix}},
	abstract = {{LiDAR} point clouds, which are usually scanned by rotating {LiDAR} sensors continuously, capture precise geometry of the surrounding environment and are crucial to many autonomous detection and navigation tasks. Though many 3D deep architectures have been developed, efficient collection and annotation of large amounts of point clouds remain one major challenge in the analytic and understanding of point cloud data. This paper presents {PolarMix}, a point cloud augmentation technique that is simple and generic but can mitigate the data constraint effectively across different perception tasks and scenarios. {PolarMix} enriches point cloud distributions and preserves point cloud fidelity via two cross-scan augmentation strategies that cut, edit, and mix point clouds along the scanning direction. The first is scene-level swapping which exchanges point cloud sectors of two {LiDAR} scans that are cut along the azimuth axis. The second is instance-level rotation and paste which crops point instances from one {LiDAR} scan, rotates them by multiple angles (to create multiple copies), and paste the rotated point instances into other scans. Extensive experiments show that {PolarMix} achieves superior performance consistently across different perception tasks and scenarios. In addition, it can work as plug-and-play for various 3D deep architectures and also performs well for unsupervised domain adaptation.},
	number = {{arXiv}:2208.00223},
	publisher = {{arXiv}},
	author = {Xiao, Aoran and Huang, Jiaxing and Guan, Dayan and Cui, Kaiwen and Lu, Shijian and Shao, Ling},
	urldate = {2024-02-29},
	date = {2022-07-30},
	eprinttype = {arxiv},
	eprint = {2208.00223 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@inproceedings{sheshappanavar_patchaugment_2021,
	location = {Montreal, {BC}, Canada},
	title = {{PatchAugment}: Local Neighborhood Augmentation in Point Cloud Classification},
	isbn = {978-1-66540-191-3},
	url = {https://ieeexplore.ieee.org/document/9607752/},
	doi = {10.1109/ICCVW54120.2021.00240},
	shorttitle = {{PatchAugment}},
	abstract = {Recent deep neural network models trained on smaller and less diverse datasets use data augmentation to alleviate limitations such as overfitting, reduced robustness, and lower generalization. Methods using 3D datasets are among the most common to use data augmentation techniques such as random point drop, scaling, translation, rotations, and jittering. However, these data augmentation techniques are fixed and are often applied to the entire object, ignoring the object’s local geometry. Different local neighborhoods on the object surface hold a different amount of geometric complexity. Applying the same data augmentation techniques at the object level is less effective in augmenting local neighborhoods with complex structures. This paper presents {PatchAugment}, a data augmentation framework to apply different augmentation techniques to the local neighborhoods. Our experimental studies on {PointNet}++ and {DGCNN} models demonstrate the effectiveness of {PatchAugment} on the task of 3D Point Cloud Classification. We evaluated our technique against these models using four benchmark datasets, {ModelNet}40 (synthetic), {ModelNet}10 (synthetic), {SHREC}’16 (synthetic) and {ScanObjectNN} (real-world).},
	eventtitle = {2021 {IEEE}/{CVF} International Conference on Computer Vision Workshops ({ICCVW})},
	pages = {2118--2127},
	booktitle = {2021 {IEEE}/{CVF} International Conference on Computer Vision Workshops ({ICCVW})},
	publisher = {{IEEE}},
	author = {Sheshappanavar, Shivanand Venkanna and Singh, Vinit Veerendraveer and Kambhamettu, Chandra},
	urldate = {2024-02-29},
	date = {2021-10},
	langid = {english},
}
